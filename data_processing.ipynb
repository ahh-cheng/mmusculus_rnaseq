{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script for fastqc\n",
    "\n",
    "After downloading all the fastq files from Nanuq server, they were transfered to calculon `/scratch/chengar2/geneD` batch by batch to avoid overcrowding the storage.\n",
    "\n",
    "First task is to evaluate the integrity of the files and check for error/corruption during file transfer using `FastQC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=fastqc\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --mem=8gb\n",
    "#SBATCH --output=/home/chengar2/geneD/fastqc_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/fastqc_%A.err\n",
    "\n",
    "start=`date +%s`\n",
    "echo job submitted on $(date) to $HOSTNAME\n",
    "\n",
    "module load fastqc/0.11.8\n",
    "\n",
    "fq=/scratch/chengar2/geneD/*.fastq.gz\n",
    "\n",
    "fastqc $fq\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "echo job completed on $(date) taking $runtime seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script for trimmomatic (last update 20191221)\n",
    "\n",
    "I made specific adapter set to match the adapter sets provided by Nanuq. The file is saved as `/scratch/chengar2/geneD/adapter.fa`\n",
    "\n",
    "    >Read1\n",
    "    AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC\n",
    "    >Read2\n",
    "    AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT\n",
    "    >Read1_rc\n",
    "    GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT\n",
    "    >Read2_rc\n",
    "    ACACTCTTTCCCTACACGACGCTCTTCCGATCT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I couldn't load trimmomatic like I loaded FastQC for some reason... Ended up having to dig up the path to the `.jar` files to use trimmomatic. \n",
    "\n",
    "These trimmed files are __NOT__ meant to be deposited into EMBI repository since they don't accept quality-trimmed fastq (as of SOX2 paper submission; rules could have changed).\n",
    "\n",
    "I hard coded the name and the path of the `fastq` files in this section; would not recommend this method. See other sections below for using for loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=trim_test\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --mem=8gb\n",
    "#SBATCH --output=/home/chengar2/geneD/trim_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/trim_%A.err\n",
    "\n",
    "start=`date +%s`\n",
    "echo $HOSTNAME\n",
    "date\n",
    "\n",
    "module load trimmomatic/0.39\n",
    "\n",
    "outpath=/scratch/chengar2/geneD/qual_trim/\n",
    "trim_p1=.trim.paired.1.fq.gz\n",
    "trim_u1=.trim.UNpaired.1.fq.gz\n",
    "trim_p2=.trim.paired.2.fq.gz\n",
    "trim_u2=.trim.UNpaired.2.fq.gz\n",
    "\n",
    "fq1=/scratch/chengar2/geneD/NS.1238.004.NEBNext_dual_i7_F2---NEBNext_dual_i5_F2.KO3-LP3_R1.fastq.gz\n",
    "fq2=/scratch/chengar2/geneD/NS.1238.004.NEBNext_dual_i7_F2---NEBNext_dual_i5_F2.KO3-LP3_R2.fastq.gz\n",
    "\n",
    "java -jar /cm/shared/apps/trimmomatic/0.39/trimmomatic-0.39.jar PE \\\n",
    "-threads 4 \\\n",
    "-phred33 \\\n",
    "$fq1 $fq2 \\\n",
    "$outpath${fq1:76:10}$trim_p1 \\\n",
    "$outpath${fq1:76:10}$trim_u1 \\\n",
    "$outpath${fq2:76:10}$trim_p2 \\\n",
    "$outpath${fq2:76:10}$trim_u2 \\\n",
    "ILLUMINACLIP:/scratch/chengar2/geneD/adapter.fa:2:30:10 \\\n",
    "LEADING:3 \\\n",
    "TRAILING:3 \\\n",
    "SLIDINGWINDOW:4:15 \\\n",
    "MINLEN:36\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "date\n",
    "echo $runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download genome files:\n",
    "\n",
    "GTF gene annotation and genome sequence is downloaded from here: https://useast.ensembl.org/info/data/ftp/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=trim_test\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --mem=5gb\n",
    "#SBATCH --output=/home/chengar2/geneD/wget_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/wget_%A.err\n",
    "\n",
    "start=`date +%s`\n",
    "echo $HOSTNAME\n",
    "date\n",
    "\n",
    "#GTF gene annotation\n",
    "wget -P /scratch/chengar2/geneD/gtf ftp://ftp.ensembl.org/pub/release-98/gtf/mus_musculus/*\n",
    "\n",
    "#genome sequence\n",
    "wget -P /scratch/chengar2/geneD/dna ftp://ftp.ensembl.org/pub/release-98/fasta/mus_musculus/dna/*\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "date\n",
    "echo $runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building genome index ###\n",
    "\n",
    "After unzipping the toplevel.fa.gz, I built a large index using bowtie2 with the code below. Output files are in `/scratch/chengar2/geneD/dna/`\n",
    "\n",
    "> #### Primary assembly vs Top level?\n",
    "\"The short answer is to choose the \"Primary assembly\" (i.e. Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz) as it does not contain the haplotype information. The top level file contains additional sequences that are relatively common variants to the reference. Most mappers available now don't specifically handle these haplo sequences and as such they will appear as simply another contig, therefore complicating the alignment. Perhaps in future, mappers might be better able to handle these hypervariable regions.\"  \n",
    "--http://genomespot.blogspot.com/2015/06/mapping-ngs-data-which-genome-version.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below is for building the index with **Bowtie2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=index\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=24\n",
    "#SBATCH --mem=24gb\n",
    "#SBATCH --output=/home/chengar2/geneD/index_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/index_%A.err\n",
    "\n",
    "start=`date +%s`\n",
    "echo job submitted on $(date) to $HOSTNAME\n",
    "\n",
    "module load bowtie2/2.3.4.3\n",
    "\n",
    "gunzip -c /scratch/chengar2/geneD/dna/Mus_musculus.GRCm38.dna.toplevel.fa.gz >/scratch/chengar2/geneD/dna/Mus_musculus.GRCm38.dna.toplevel.fa\n",
    "\n",
    "bowtie2-build --large-index --threads 24 /scratch/chengar2/geneD/dna/Mus_musculus.GRCm38.dna.toplevel.fa \\\n",
    "/scratch/chengar2/geneD/dna/Mus_musculus.GRCm38.dna.toplevel\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "echo job completed on $(date) taking $runtime seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below is for building the index with **Bowtie2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=index-pri\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=15\n",
    "#SBATCH --mem=40gb\n",
    "#SBATCH --output=/home/chengar2/geneD/pri-assem_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/pri-assem_%A.err\n",
    "\n",
    "start=`date +%s`\n",
    "echo job submitted on $(date) to $HOSTNAME\n",
    "\n",
    "module load bowtie2/2.3.4.3\n",
    "\n",
    "gunzip -c /scratch/chengar2/geneD/dna/Mus_musculus.GRCm38.dna.primary_assembly.fa.gz >/scratch/chengar2/geneD/dna/Mus_musculus.GRCm38.dna.primary_assembly.fa\n",
    "\n",
    "bowtie2-build --large-index --threads 24 /scratch/chengar2/geneD/dna/Mus_musculus.GRCm38.dna.primary_assembly.fa \\\n",
    "/scratch/chengar2/geneD/dna/Mus_musculus.GRCm38.dna.primary_assembly\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "echo job completed on $(date) taking $runtime seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building genome index v2\n",
    "\n",
    "`hisat2` is supposedly an improved version of `bowtie2` that is better at identifying reads that span over an intron. To prepare alignment with `hisat2`, I indexed the mouse reference genome again with `hisat2-build`, in two different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below is for building the index with **hisat2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=index\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=24\n",
    "#SBATCH --mem=24gb\n",
    "#SBATCH --output=/home/chengar2/geneD/index_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/index_%A.err\n",
    "\n",
    "start=`date +%s`\n",
    "echo job submitted on $(date) to $HOSTNAME\n",
    "\n",
    "module load hisat2/2.1.0\n",
    "\n",
    "hisat2-build --large-index --threads 24 /scratch/chengar2/geneD/dna/Mus_musculus.GRCm38.dna.toplevel.fa \\\n",
    "/scratch/chengar2/geneD/dna/Mus_musculus.GRCm38.dna.toplevel\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "echo job completed on $(date) taking $runtime seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below is for building the index with **hisat2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=index\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=15\n",
    "#SBATCH --mem=40gb\n",
    "#SBATCH --output=/home/chengar2/geneD/index_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/index_%A.err\n",
    "\n",
    "start=`date +%s`\n",
    "echo job submitted on $(date) to $HOSTNAME\n",
    "\n",
    "module load hisat2/2.1.0\n",
    "\n",
    "hisat2-build --large-index --threads 15 /scratch/chengar2/geneD/dna/Mus_musculus.GRCm38.dna.primary_assembly.fa \\\n",
    "/scratch/chengar2/geneD/dna/Mus_musculus.GRCm38.dna.primary_assembly\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "echo job completed on $(date) taking $runtime seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Alignment\n",
    "\n",
    "There is countless modules (bwa, bowtie, tophat, hisat, salmon, STAR etc) made for aligning RNA-seq data to a reference genome and each has its own strength and drawback.\n",
    "\n",
    "I used both `bowtie2` and `hisat2` for alignment here and explored their performance in handling transcriptomic data.\n",
    "\n",
    "P.S. `hisat2` runs a lot faster than `bowtie2` (2 vs ~4+ hours per files) with equal resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Code below is for alignment with **`Bowtie2`** using **`toplevel`** index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=align\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=6\n",
    "#SBATCH --mem=18gb\n",
    "#SBATCH --output=/home/chengar2/geneD/align_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/align_%A.err\n",
    "\n",
    "start=`date +%s`\n",
    "echo job submitted on $(date) to $HOSTNAME\n",
    "\n",
    "module load bowtie2/2.3.4.3\n",
    "\n",
    "for fq in /scratch/chengar2/geneD/qual_trim/*.trim.paired.1.fq.gz\n",
    "do\n",
    "    echo \"running analysis on ${fq:34:7}\"\n",
    "    name=${fq:34:7}\n",
    "    filebase=${fq:0:41}\n",
    "    filebase1=${fq:0:44}\n",
    "    filebase2=${fq:0:43}2\n",
    "    bowtie2 --un-gz $filebase.unpaired.unmapped.reads.fq \\\n",
    "    --un-conc-gz $filebase.paired.discordant.reads.fq \\\n",
    "    --met-file $filebase.metrics --rg-lsid $name \\\n",
    "    -x /scratch/chengar2/geneD/dna/Mus_musculus.GRCm38.dna.toplevel \\\n",
    "    -1 $filebase1.trim.paired.1.fq.gz \\\n",
    "    -2 $filebase2.trim.paired.2.fq.gz \\\n",
    "    -U $filebase1.trim.UNpaired.1.fq.gz,$filebase2.trim.UNpaired.2.fq.gz \\\n",
    "    -S $filebase.sam 2>$filebase.stderr.txt\n",
    "done\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "echo job completed on $(date) taking $runtime seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below is for alignment with **`Bowtie2`** using **`primary assembly`** index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=bowtie2_pri\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=6\n",
    "#SBATCH --mem=24gb\n",
    "#SBATCH --output=/home/chengar2/geneD/bowtie2_pri_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/bowtie2_pri_%A.err\n",
    "\n",
    "start=`date +%s`\n",
    "echo job submitted on $(date) to $HOSTNAME\n",
    "\n",
    "module load bowtie2/2.3.4.3\n",
    "\n",
    "for fq in /scratch/chengar2/geneD/hisat2/*.trim.paired.1.fq.gz\n",
    "do\n",
    "    filebase=${fq:0:38}\n",
    "    filebase1=${fq:0:41}\n",
    "    filebase2=${fq:0:40}2\n",
    "    name=${fq:31:7}\n",
    "    echo \"running analysis for $name on $(date)\"\n",
    "    bowtie2 --un-gz $filebase.pri.bow2.unpaired.unmapped.reads.fq \\\n",
    "    --un-conc-gz $filebase.pri.bow2.paired.discordant.reads.fq \\\n",
    "    --met-file $filebase.pri.bow2.metrics --rg-id geneD_$name --rg LB:lib1 --rg PL:illumina --rg SM:$name --rg PU:unit1 \\\n",
    "    -x /scratch/chengar2/geneD/dna/Mus_musculus.GRCm38.dna.primary_assembly\\\n",
    "    -1 $filebase1.trim.paired.1.fq.gz \\\n",
    "    -2 $filebase2.trim.paired.2.fq.gz \\\n",
    "    -U $filebase1.trim.UNpaired.1.fq.gz,$filebase2.trim.UNpaired.2.fq.gz \\\n",
    "    -S $filebase.pri.bow2.sam 2>$filebase.pri.bow2.stderr.txt\n",
    "done\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "echo job completed on $(date) taking $runtime seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment v2 - hisat2\n",
    "\n",
    "I ran a test with `hisat2` to evaluate the performance of the program. Turns out `hisat2` performance is far better than `bowtie2` using `toplevel` index (98.51% vs 84.75%). ~14% might seems inconsequential however we are dealing with 43 millions reads, 14% is roughly 6 millions read!! In addition if we focus on number of reads that \"aligned concordantly exactly 1 time\", we see a huge % difference (91.17% vs 52.7%); along the same line there is 10 times less reads that \"aligned concordantly 0 times\" (1.3mil vs 14mil) when I use `hisat2`. \n",
    "\n",
    "**Sample: KO1-DD1; `hisat2` using `toplevel` index**  ---------------------------------------------------------------------  \n",
    "43922113 reads; of these:\n",
    "\n",
    "    >42760471 (97.36%) were paired; of these:  \n",
    "        >>1384617 (3.24%) aligned concordantly 0 times  \n",
    "        >>38984529 (91.17%) aligned concordantly exactly 1 time  \n",
    "        >>2391325 (5.59%) aligned concordantly >1 times  \n",
    "    \n",
    "        >>1384617 pairs aligned concordantly 0 times; of these:  \n",
    "            >>>345607 (24.96%) aligned discordantly 1 time\n",
    "        \n",
    "        >>1039010 pairs aligned 0 times concordantly or discordantly; of these:  \n",
    "            >>>2078020 mates make up the pairs; of these:  \n",
    "                >>>>1106485 (53.25%) aligned 0 times  \n",
    "                >>>>726118 (34.94%) aligned exactly 1 time  \n",
    "                >>>>245417 (11.81%) aligned >1 times  \n",
    "    >1161642 (2.64%) were unpaired; of these:  \n",
    "        >>184642 (15.89%) aligned 0 times  \n",
    "        >>902367 (77.68%) aligned exactly 1 time  \n",
    "        >>74633 (6.42%) aligned >1 times  \n",
    "**98.51% overall alignment rate**\n",
    "\n",
    "---\n",
    "\n",
    "**Sample: KO1-DD1; `bowtie2` using `toplevel` index**  -----------------------------------------------------------------------  \n",
    "43922113 reads; of these:\n",
    "  \n",
    "    >42760471 (97.36%) were paired; of these:\n",
    "        >>14473868 (33.85%) aligned concordantly 0 times\n",
    "        >>22533086 (52.70%) aligned concordantly exactly 1 time\n",
    "        >>5753517 (13.46%) aligned concordantly >1 times\n",
    "    \n",
    "        >>14473868 pairs aligned concordantly 0 times; of these:\n",
    "          >>>3701127 (25.57%) aligned discordantly 1 time\n",
    "    \n",
    "        >>10772741 pairs aligned 0 times concordantly or discordantly; of these:\n",
    "          >>>21545482 mates make up the pairs; of these:\n",
    "            >>>>12959303 (60.15%) aligned 0 times\n",
    "            >>>>7400580 (34.35%) aligned exactly 1 time\n",
    "            >>>>1185599 (5.50%) aligned >1 times\n",
    "    >1161642 (2.64%) were unpaired; of these:\n",
    "        >>260480 (22.42%) aligned 0 times\n",
    "        >>724215 (62.34%) aligned exactly 1 time\n",
    "        >>176947 (15.23%) aligned >1 times\n",
    "**84.75% overall alignment rate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":-----------------------------------------------------------------------------------------------------------------------------  \n",
    "On another note, when I switched the index file to  `primary assembly` instead of `toplevel`, the alignment % interesting remained practically the same (0.2% lower). However it is also worth noting that more reads aligned concordantly exactly once (92.67% vs 91.17%) while less reads aligned concordantly >1 times (4.08% vs 5.59%) when I switched to `primary assembly`. \n",
    "\n",
    "Since `hisat2` runs pretty fast, we can align all of our `fastq` to both `primary assembly` and `toplevel` index to allow a better comparison. \n",
    "\n",
    "**Sample: KO1-DD1; `hisat2` using `primary assembly` index**------------------------------------------------------------    \n",
    "43922113 reads; of these:\n",
    "     \n",
    "    >42760471 (97.36%) were paired; of these:\n",
    "        >>1391064 (3.25%) aligned concordantly 0 times\n",
    "        >>39625929 (92.67%) aligned concordantly exactly 1 time\n",
    "        >>1743478 (4.08%) aligned concordantly >1 times\n",
    "    \n",
    "        >>1391064 pairs aligned concordantly 0 times; of these:\n",
    "          >>>352189 (25.32%) aligned discordantly 1 time\n",
    "    \n",
    "        >>1038875 pairs aligned 0 times concordantly or discordantly; of these:\n",
    "          >>>2077750 mates make up the pairs; of these:\n",
    "            >>>>1122062 (54.00%) aligned 0 times\n",
    "            >>>>735210 (35.38%) aligned exactly 1 time\n",
    "            >>>>220478 (10.61%) aligned >1 times\n",
    "    >1161642 (2.64%) were unpaired; of these:\n",
    "        >>184979 (15.92%) aligned 0 times\n",
    "        >>918263 (79.05%) aligned exactly 1 time\n",
    "        >>58400 (5.03%) aligned >1 times\n",
    "**98.49% overall alignment rate**\n",
    "\n",
    "**Sample: KO1-DD1; `bowtie2` using `primary assembly` index**------------------------------------------------------------    \n",
    "43922113 reads; of these:\n",
    "\n",
    "    >42760471 (97.36%) were paired; of these:\n",
    "        >>14479664 (33.86%) aligned concordantly 0 times\n",
    "        >>22962797 (53.70%) aligned concordantly exactly 1 time\n",
    "        >>5318010 (12.44%) aligned concordantly >1 times\n",
    "    \n",
    "        >>14479664 pairs aligned concordantly 0 times; of these:\n",
    "          >>>3764337 (26.00%) aligned discordantly 1 time\n",
    "\n",
    "        >>10715327 pairs aligned 0 times concordantly or discordantly; of these:\n",
    "          >>>21430654 mates make up the pairs; of these:\n",
    "            >>>>12975281 (60.55%) aligned 0 times\n",
    "            >>>>7510451 (35.05%) aligned exactly 1 time\n",
    "            >>>>944922 (4.41%) aligned >1 times\n",
    "    >1161642 (2.64%) were unpaired; of these:\n",
    "        >>260830 (22.45%) aligned 0 times\n",
    "        >>738323 (63.56%) aligned exactly 1 time\n",
    "        >>162489 (13.99%) aligned >1 times\n",
    "**84.73% overall alignment rate**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below is for alignment with **`hisat2`** using **`toplevel`** index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=hisat2\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=6\n",
    "#SBATCH --mem=18gb\n",
    "#SBATCH --output=/home/chengar2/geneD/hisat2-align_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/hisat2-align_%A.err\n",
    "\n",
    "start=`date +%s`\n",
    "echo job submitted on $(date) to $HOSTNAME\n",
    "\n",
    "module load hisat2/2.1.0\n",
    "\n",
    "for fq in /scratch/chengar2/geneD/hisat2/*.trim.paired.1.fq.gz\n",
    "do\n",
    "    filebase=${fq:0:38}\n",
    "    filebase1=${fq:0:41}\n",
    "    filebase2=${fq:0:40}2\n",
    "    name=${fq:31:7}\n",
    "    echo \"running analysis for $name on $(date)\"\n",
    "    hisat2 --un-gz $filebase.hisat2.unpaired.unmapped.reads.fq \\\n",
    "    --un-conc-gz $filebase.hisat2.paired.discordant.reads.fq \\\n",
    "    --met-file $filebase.hisat2.metrics --rg-id geneD_$name --rg LB:lib1 --rg PL:illumina --rg SM:$name --rg PU:unit1 \\\n",
    "    -x /scratch/chengar2/geneD/dna/Mus_musculus.GRCm38.dna.toplevel \\\n",
    "    -1 $filebase1.trim.paired.1.fq.gz \\\n",
    "    -2 $filebase2.trim.paired.2.fq.gz \\\n",
    "    -U $filebase1.trim.UNpaired.1.fq.gz,$filebase2.trim.UNpaired.2.fq.gz \\\n",
    "    -S $filebase.hisat2.sam 2>$filebase.hisat2.stderr.txt\n",
    "    echo \"analysis complete for $name on $(date)\"\n",
    "done\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "echo job completed on $(date) taking $runtime seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below is for alignment with **`hisat2`** using **`primary assembly`** index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=hisat2\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=6\n",
    "#SBATCH --mem=18gb\n",
    "#SBATCH --output=/home/chengar2/geneD/hisat2_pri-align_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/hisat2_pri-align_%A.err\n",
    "\n",
    "start=`date +%s`\n",
    "echo job submitted on $(date) to $HOSTNAME\n",
    "\n",
    "module load hisat2/2.1.0\n",
    "\n",
    "for fq in /scratch/chengar2/geneD/hisat2/*.trim.paired.1.fq.gz\n",
    "do\n",
    "    filebase=${fq:0:38}\n",
    "    filebase1=${fq:0:41}\n",
    "    filebase2=${fq:0:40}2\n",
    "    name=${fq:31:7}\n",
    "    echo \"running analysis for $name on $(date)\"\n",
    "    hisat2 --un-gz $filebase.pri.hisat2.unpaired.unmapped.reads.fq \\\n",
    "    --un-conc-gz $filebase.pri.hisat2.paired.discordant.reads.fq \\\n",
    "    --met-file $filebase.pri.hisat2.metrics --rg-id geneD_$name --rg LB:lib1 --rg PL:illumina --rg SM:$name --rg PU:unit1 \\\n",
    "    -x /scratch/chengar2/geneD/dna/Mus_musculus.GRCm38.dna.primary_assembly \\\n",
    "    -1 $filebase1.trim.paired.1.fq.gz \\\n",
    "    -2 $filebase2.trim.paired.2.fq.gz \\\n",
    "    -U $filebase1.trim.UNpaired.1.fq.gz,$filebase2.trim.UNpaired.2.fq.gz \\\n",
    "    -S $filebase.pri.hisat2.sam 2>$filebase.pri.hisat2.stderr.txt\n",
    "    echo \"analysis complete for $name on $(date)\"\n",
    "done\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "echo job completed on $(date) taking $runtime seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment v3 - Strandness\n",
    "\n",
    "\n",
    "Assuming Genome Quebec is still using the same dUTP library preparation for the SOX2 paper, our RNA-seq should be strand-specific and the library strand should be first strand:\n",
    "\n",
    ">\"cDNA synthesis was achieved with the NEBNext RNA First Strand Synthesis and `NEBNext Ultra Directional RNA Second Strand Synthesis Modules (New England BioLabs)`. The remaining steps of library preparation were done using the NEBNext Ultra II DNA Library Prep Kit for Illumina (New England BioLabs). Adapters and PCR primers were purchased from New England BioLabs. \" -- Genome Quebec protocol for SOX2 paper\n",
    ">>NEB protocol: https://international.neb.com/products/e7550-nebnext-ultra-directional-rna-second-strand-synthesis-module#Product%20Information\n",
    "__TL;DR__ dUTP was incorporated during the second strand synthesis and digested after adapter ligation, leaving only the first cDNA strand (reverse complement of the mRNA) to form the library. Thus the library strand is the first strand by EBI/ENA definition\n",
    "\n",
    ">Overview of strand-specific library preparation: https://github.com/igordot/genomics/blob/master/notes/rna-seq-strand.md\n",
    "\n",
    ">More discussion on strandness with a great representative image at the bottom of the page https://www.biostars.org/p/98756/\n",
    "\n",
    "And we can confirm this by visualizing one of our indexed `bam` files with IGV. Example images are from `filtered_WT1-DD1.bam` using `hisat2` and `primary_assembly` for alignment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Gene is on negative strand\n",
    "\n",
    "![Stox2](gene_on_neg.png)\n",
    "\n",
    "**Observation** \n",
    "- There is a lot more **red** alignments than **blue** alignments. \n",
    "- There is actually a lot more **red** alignments when you scroll further down. There is so many **red** I can't capture all of them in one frame.\n",
    "- Blue means read 1 of the pair is aligned to negative strand; red means read 1 of the pair is aligned to the positive strand\n",
    "- Reference genome shows this gene `Stox2` is encoded on the negative strand (solid blue bar at the bottom with \"<\" showing directionality)\n",
    "\n",
    "**Interpretation**  \n",
    "- No. of Red alignments >> No. of Blue  alignments -> this is definitely stranded. (Not surprising; if you go to Nanuq page where `fastq` can be downloaded, there is a column called `\"library type\"` with the value of `\"mRNA stranded\"`)\n",
    "- **Most** read 2 of the pair aligned to the negative strand, which make sense because if the library strand is the reverse complement of the mRNA -> read 1 will align on the template strand; read 2 will align on the coding strand.\n",
    "\n",
    "**Summary**\n",
    "- R2 aligned on negative strand while ref. genome shows the gene is encoded by the negative strand == first strand is library strand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Gene is on positive strand\n",
    "\n",
    "![Sox2](gene_on_pos.png)\n",
    "\n",
    "**Observation** \n",
    "- There is a lot more **blue** alignments than **red** alignments. \n",
    "- There is actually a lot more **blue** alignments when you scroll further up. There is so many **blue** I can't capture all of them in one frame.\n",
    "- Blue means read 1 of the pair is aligned to negative strand; red means read 1 of the pair is aligned to the positive strand\n",
    "- Reference genome shows this gene `Sox2` is encoded on the positive strand (solid blue bar at the bottom with \">\" showing directionality)\n",
    "\n",
    "**Interpretation**  \n",
    "- No. of Blue alignments >> No. of Red  alignments -> this is definitely stranded. (Once again not surprising)\n",
    "- **Most** read 2 of the pair aligned to the positive strand, which make sense because if the library strand is the reverse complement of the mRNA -> read 1 will align on the template strand; read 2 will align on the coding strand.\n",
    "\n",
    "**Summary**\n",
    "- R2 aligned on positive strand while ref. genome shows the gene is encoded by the positive strand == first strand is library strand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Would this change the way we code? \n",
    "\n",
    "There is the option `--rna-strandness` for user to specify strandness of the library in `hisat2`, which means in our case we can type `--rna-strandness RF` to let `hisat2` know our library strand is the first strand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=strand\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=6\n",
    "#SBATCH --mem=24gb\n",
    "#SBATCH --output=/home/chengar2/geneD/strand_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/strand_%A.err\n",
    "\n",
    "start=`date +%s`\n",
    "echo job submitted on $(date) to $HOSTNAME\n",
    "\n",
    "module load hisat2/2.1.0\n",
    "\n",
    "for fq in /scratch/chengar2/geneD/hisat2/*.trim.paired.1.fq.gz\n",
    "do\n",
    "    filebase=${fq:0:38}\n",
    "    filebase1=${fq:0:41}\n",
    "    filebase2=${fq:0:40}2\n",
    "    name=${fq:31:7}\n",
    "    echo \"running analysis for $name on $(date)\"\n",
    "    hisat2 --rna-strandness RF -p 6 \\\n",
    "    --un-gz $filebase.pri.hisat2.unpaired.unmapped.reads.fq \\\n",
    "    --un-conc-gz $filebase.pri.hisat2.paired.discordant.reads.fq \\\n",
    "    --met-file $filebase.pri.hisat2.metrics --rg-id geneD_$name --rg LB:lib1 --rg PL:illumina --rg SM:$name --rg PU:unit1 \\\n",
    "    -x /scratch/chengar2/geneD/dna/Mus_musculus.GRCm38.dna.primary_assembly \\\n",
    "    -1 $filebase1.trim.paired.1.fq.gz \\\n",
    "    -2 $filebase2.trim.paired.2.fq.gz \\\n",
    "    -U $filebase1.trim.UNpaired.1.fq.gz,$filebase2.trim.UNpaired.2.fq.gz \\\n",
    "    -S $filebase.pri.hisat2.sam 2>$filebase.pri.hisat2.stderr.txt\n",
    "    echo \"analysis complete for $name on $(date)\"\n",
    "done\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "echo job completed on $(date) taking $runtime seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality check with Picard\n",
    "To make sure the alignments are done properly, we can use picard ValidateSamFile function to check for anomalies in the Sam files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=picard\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=6\n",
    "#SBATCH --mem=24gb\n",
    "#SBATCH --output=/home/chengar2/geneD/picard_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/picard_%A.err\n",
    "\n",
    "\n",
    "start=`date +%s`\n",
    "echo job submitted on $(date) to $HOSTNAME\n",
    "\n",
    "module load picard/2.13\n",
    "\n",
    "for sam in /scratch/chengar2/geneD/qual_trim/*.sam\n",
    "do\n",
    "    extract=$(echo $sam | awk -F\".\" '{print $1}')\n",
    "    name=$(echo $extract | awk -F\"/\" '{print $NF}')\n",
    "    echo \"running analysis for $name on $(date)\"\n",
    "    java -jar /cm/shared/apps/picard/2.13/picard.jar ValidateSamFile I=$sam MODE=SUMMARY \\\n",
    "    O=/scratch/chengar2/geneD/bam/$name.txt\n",
    "    echo \"analysis complete for $name on $(date)\"\n",
    "done\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "echo job completed on $(date) taking $runtime seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `hisat2` giving us errors!\n",
    "\n",
    "When we run `picard ValidateSamFile` on the `sam` generated by `hisat2` we encountered a problem.\n",
    "\n",
    ">ERROR: Record 178, Read name A00977:10:HWCTJDSXX:4:1101:16938:1078, Mate negative strand flag does not match read negative strand flag of mate  \n",
    "ERROR: Record 616, Read name A00977:10:HWCTJDSXX:4:1101:2528:1235, Mate negative strand flag does not match read negative strand flag of mate  \n",
    "ERROR: Record 624, Read name A00977:10:HWCTJDSXX:4:1101:6072:1235, Mate negative strand flag does not match read negative strand flag of mate  \n",
    "ERROR: Record 878, Read name A00977:10:HWCTJDSXX:4:1101:24813:1313, Mate negative strand flag does not match read negative strand flag of mate  \n",
    "ERROR: Record 904, Read name A00977:10:HWCTJDSXX:4:1101:21875:1329, Mate negative strand flag does not match read negative strand flag of mate  \n",
    "\n",
    "That is just 5 out of the ~300,000 errors in one `sam` file! They all have the same problem \"MISMATCH_FLAG_MATE_NEG_STRAND\".\n",
    "\n",
    "This gave me a huge headache but turns out to be something not too serious. A weird thing with `hisat2` is that it doesn't assign the correct tag/flag to a read when a read's mate in the pair cannot be aligned, in particular when one of them is aligned to the negative strand.\n",
    "\n",
    "To be more specific, each read gets a specific number to identify their (and their mate's) properties (e.g. read paired? read mapped in proper pair? read unmapped?....), which is encoded in the integer (89) after the read name (A00977:10:HWCTJDSXX:4:1101:20130:2816) **see read pair sample 1**. To know what 89 stands for, one would have to decode it or look it up. Luckily we can use the tool here https://broadinstitute.github.io/picard/explain-flags.html , simply input 89 into the \"SAM flag\" search box and click \"explain\", we can see that this read is: \n",
    ">\"read paired (0x1), mate unmapped (0x8), read reverse strand (0x10), first in pair (0x40)\"\n",
    "\n",
    "The proper flag for its mate should be 165 (press \"switch to mate\" to find out), which corresponds to:\n",
    ">\"read paired (0x1), read unmapped (0x4), mate reverse strand (0x20), second in pair (0x80)\"\n",
    "\n",
    "However `hisat2` gave its mate 133, which corresponds to:\n",
    ">\"read paired (0x1), read unmapped (0x4), second in pair (0x80)\"\n",
    "\n",
    "...which does not have the \"mate reverse strand\" part. `hisat2` giving it the \"wrong\" flag means we have to use `picard FixMateInformation` to correct it but the actual alignment result should be still valid. \n",
    "\n",
    "To learn more about the meaning of each field in a SAM file, see https://medium.com/@shilparaopradeep/samtools-guide-learning-how-to-filter-and-manipulate-with-sam-bam-files-2c28b25d29e8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read pair sample 1\n",
    "```bash\n",
    ">[chengar2@calculon hisat2]$ grep -in A00977:10:HWCTJDSXX:4:1101:20130:2816 KO1-DD1.pri.hisat2.sam\n",
    "5148:A00977:10:HWCTJDSXX:4:1101:20130:2816      89      9       80139057        60      91M1670N10M     =       80139057        0       AATCAGACTAAACTACGGTGATCAGTCAGCAGACGGTGGGAAGCTGCTTGAAGATGAGCTCATTGACTTCTCAGAGGATCAGGATGACCCGGATGATAGCA      FFFFFFF:F,::,FFFFFFFFFFFFFF:F,F:FF:FFFF,FFFFFF:FFF:FFFFFFF::FF,FFFFFF:FF:FFFFFFFFFFFFFFFFFFFFFF,F:F,F   AS:i:0  XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:101        YT:Z:UP RG:Z:geneD_KO1-DD1 XS:A:+  NH:i:1  \n",
    "\n",
    "\n",
    ">5149:A00977:10:HWCTJDSXX:4:1101:20130:2816      133     9       80139057        0       *       =       80139057        0       TACCGGAGAAACGCATACAGTGTAAAGTGTAGTATGAAAAAAAAAAATAATGCAATCAATGAAAATGAAGAACAAAGTAACGGAGAATAAA        FFFF:FF::FFFFFFFFFFFFFFFFFFF::FFFFFFFFF:FFFF:FFF,F,F,,FFFFF:,FFFF,FFF,:F:,FF,FFF,::,,FF,,,F     YT:Z:UP RG:Z:geneD_KO1-DD1\n",
    "                                                                                            \n",
    "```                                                                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I didn't check if all ~300,000 are like this but for the handful that I have, one of the reads in the pair is always unmapped (4th integer after the read name should be 0; it represent MAPQ/mapping quality, unmapped reads have a quality of 0), so for now I presume my conclusion is correct and simply changing the SAM flag will suffice.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read pair sample 2\n",
    "```bash\n",
    "[chengar2@calculon hisat2]$ grep -in A00977:10:HWCTJDSXX:4:1101:16685:3458 KO1-DD1.pri.hisat2.sam\n",
    "6844:A00977:10:HWCTJDSXX:4:1101:16685:3458      89      11      19924932        60      25M73163N76M    =       19924932        0       TGACCGAAGAAACACACCCGGACGATGACAGCTATATTGTGCGTGTCAAGGCTGTGGTTATGACCAGAGATGACTCCAGCGGGGGATGGTTCCCACAGGAA      FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFF   AS:i:-3 XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:101        YT:Z:UP RG:Z:geneD_KO1-DD1 XS:A:+  NH:i:1  \n",
    "\n",
    "6845:A00977:10:HWCTJDSXX:4:1101:16685:3458      133     11      19924932        0       *       =       19924932        0       CGCGGGACAGGCGTCTAGGTGAACAAGAAAATGACCGAAGAAACACACCCGGACGATGACAGCTATATTGTGCGTGTCAAGGCTGTGGTTATGACCAGAGA      FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF   YT:Z:UP RG:Z:geneD_KO1-DD1  \n",
    "\n",
    "```\n",
    "\n",
    "### Read pair sample 3\n",
    "\n",
    "```bash\n",
    "[chengar2@calculon hisat2]$ grep -in A00977:10:HWCTJDSXX:4:1101:23511:3881 KO1-DD1.pri.hisat2.sam\n",
    "7981:A00977:10:HWCTJDSXX:4:1101:23511:3881      153     17      23771415        60      6S95M   =       23771415        0       CCCTGTCGACGGCAGCGGGCCCTGCCTCTCCGGCGGCTGAGCCACCCGATCCTTCGTGTGAGTGTCCGCCAACGCAGGCGCCGGCCTAGCAGCCGGGGCTG      FFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF   AS:i:-6 XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:95 YT:Z:UP RG:Z:geneD_KO1-DD1NH:i:1\n",
    "7982:A00977:10:HWCTJDSXX:4:1101:23511:3881      69      17      23771415        0       *       =       23771415        0       CTGGCACCTTCTTCTGGAATGTCTGAAGACAGCCACAGTGTACCTTTAATTCCAGCACTCAGGAGGCAGGGGGTGGAGGAGCTCTGTGAATTTGAGGCCCA      FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFF   YT:Z:UP RG:Z:geneD_KO1-DD1\n",
    "```\n",
    "\n",
    "### Read pair sample 4\n",
    "```bash\n",
    "[chengar2@calculon hisat2]$ grep -in A00977:10:HWCTJDSXX:4:1101:25527:4554 KO1-DD1.pri.hisat2.sam\n",
    "10163:A00977:10:HWCTJDSXX:4:1101:25527:4554     153     13      9054582 1       88M     =       9054582 0       TTTTTTTTTTTTTTTTTTTTTTTCCAGAGCTGAGGACCGAACCCAGGGCCTTGCGCTTGCTAGGCAAGCGCTCTACCACTGAGCTAAA        FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF,FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFF   AS:i:0  ZS:i:0  XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:88 YT:Z:UP RG:Z:geneD_KO1-DD1      NH:i:4\n",
    "10164:A00977:10:HWCTJDSXX:4:1101:25527:4554     393     7       144914481       1       88M     =       144914481       0       TTTAGCTCAGTGGTAGAGCGCTTGCCTAGCAAGCGCAAGGCCCTGGGTTCGGTCCTCAGCTCTGGAAAAAAAAAAAAAAAAAAAAAAA   FFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF,FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF        AS:i:0  ZS:i:0  XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:88 YT:Z:UP RG:Z:geneD_KO1-DD1      NH:i:4\n",
    "10165:A00977:10:HWCTJDSXX:4:1101:25527:4554     409     8       126503341       1       88M     =       126503341       0       TTTTTTTTTTTTTTTTTTTTTTTCCAGAGCTGAGGACCGAACCCAGGGCCTTGCGCTTGCTAGGCAAGCGCTCTACCACTGAGCTAAA   FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF,FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFF        AS:i:0  ZS:i:0  XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:88 YT:Z:UP RG:Z:geneD_KO1-DD1      NH:i:4\n",
    "10166:A00977:10:HWCTJDSXX:4:1101:25527:4554     393     5       12155114        1       88M     =       12155114        0       TTTAGCTCAGTGGTAGAGCGCTTGCCTAGCAAGCGCAAGGCCCTGGGTTCGGTCCTCAGCTCTGGAAAAAAAAAAAAAAAAAAAAAAA   FFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF,FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF        AS:i:0  ZS:i:0  XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:88 YT:Z:UP RG:Z:geneD_KO1-DD1      NH:i:4\n",
    "10167:A00977:10:HWCTJDSXX:4:1101:25527:4554     69      13      9054582 0       *       =       9054582 0       CCTTGTTTTTTTTTTGGTCTTTTTGTTATTTTGTCTTTTTTTTTTTTTTTTTTTTTTTTAAAGAGCTTAGGCACGAACACAGGGCCTTG       F,FFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FF::FF:,F,F,,F,::,,:F,FF,,:F,FF,F,::  YT:Z:UP RG:Z:geneD_KO1-DD1\n",
    "\n",
    "```\n",
    "\n",
    "### Read pair sample 5\n",
    "\n",
    "```bash\n",
    "[chengar2@calculon hisat2]$ grep -in A00977:10:HWCTJDSXX:4:1101:27227:7435 KO1-DD1.pri.hisat2.sam\n",
    "18179:A00977:10:HWCTJDSXX:4:1101:27227:7435     89      5       31452510        60      68M12874N33M    =       31452510        0       AGCCCTTGGGTGAAATTGTTAGGCGTGGAGGGGGAGTGATGTCTTCCAGACTCGGTGCAGTCACCGCCGGCCCAGTGCTCCATAAAGGATAACAGTTTCCA      FFFFFF:F:FFFFFFFFFFFFFFF:FFFFFFFFFFFFFF:::FFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFF   AS:i:-1 XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:101        YT:Z:UP RG:Z:geneD_KO1-DD1 XS:A:+  NH:i:1\n",
    "18180:A00977:10:HWCTJDSXX:4:1101:27227:7435     133     5       31452510        0       *       =       31452510        0       TTGGTCTGTCCGGAGCCCAGGGGTGAAATTGTTAGGCGTGGAGGGGGAGTTATGTCTTCCAGAATCGGTGCAGTAACCCCCGGCCCACTGCTCCATAAA        FF,FFFF:FFF:FF,FF:,,:FFF,FFF,F:FFFF:,:FFFF,FFFFF:F:FF,F,::,,F,F,,:FFFFFF,,,F:,,F:FFFFF:,,:FF,,F,FFF     YT:Z:UP RG:Z:geneD_KO1-DD1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below is for fixing mate pairs' SAM flag with **`picard FixMateInformation`**. Run **`ValidateSamFile`** again after this is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=picard_fm\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=6\n",
    "#SBATCH --mem=24gb\n",
    "#SBATCH --output=/home/chengar2/geneD/picard_fm_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/picard_fm_%A.err\n",
    "\n",
    "\n",
    "start=`date +%s`\n",
    "echo job submitted on $(date) to $HOSTNAME\n",
    "\n",
    "module load picard/2.13\n",
    "\n",
    "for sam in /scratch/chengar2/geneD/hisat2/*pri.hisat2.sam \n",
    "\n",
    "do\n",
    "    extract=$(echo $sam | awk -F\".\" '{print $1\".\"$2\".\"$3}')\n",
    "    name=$(echo $extract | awk -F\"/\" '{print $NF}')\n",
    "    echo \"running analysis for $name on $(date)\"\n",
    "    java -jar /cm/shared/apps/picard/2.13/picard.jar FixMateInformation I=$sam \\\n",
    "    O=/scratch/chengar2/geneD/hisat2/fixed_mate_$name.sam\n",
    "    echo \"analysis complete for $name on $(date)\"\n",
    "done\n",
    "\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "echo job completed on $(date) taking $runtime seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting and Compressing\n",
    "\n",
    "Reads in SAM files are then sorted by chromosome coordinates and compressed into BAM files.\n",
    "\n",
    "I used samtools `sort` function to do the job.  \n",
    "`-T` path to output temporary files and the naming scheme    \n",
    "`-O` output format; set to `bam` for compression  \n",
    "`-o` path to output `bam` files and naming scheme  \n",
    "`-@` no. of threads should be used  \n",
    "\n",
    "Some program such as `picard`'s `MarkDuplicates` required the `bam` files to be sorted by coordinate. However `featureCounts` required the files to be sorted by queryname (otherwise some files might be mistaken as single-end sequencing). Use `-n` flag if you need to sort by queryname."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=bam\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=6\n",
    "#SBATCH --mem=24gb\n",
    "#SBATCH --output=/home/chengar2/geneD/bam_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/bam_%A.err\n",
    "\n",
    "\n",
    "start=`date +%s`\n",
    "echo job submitted on $(date) to $HOSTNAME\n",
    "\n",
    "module load samtools/1.9\n",
    "\n",
    "for sam in /scratch/chengar2/geneD/hisat2/fixed_mate_*pri.hisat2.sam\n",
    "do\n",
    "    extract=$(echo $sam | awk -F\".\" '{print $1\".\"$2\".\"$3}')\n",
    "    name=$(echo $extract | awk -F\"/\" '{print $NF}')\n",
    "    echo \"running analysis for $name on $(date)\"\n",
    "    samtools sort -T /scratch/chengar2/geneD/bam/$name.sorting.tmp \\\n",
    "    -O bam -o /scratch/chengar2/geneD/bam/$name.sorted.bam -@ 6 $sam\n",
    "    echo \"analysis complete for $name on $(date)\"\n",
    "done\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "echo job completed on $(date) taking $runtime seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran another round of picard `ValidateSamFile` after the sorting and compression just to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=picard\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=6\n",
    "#SBATCH --mem=24gb\n",
    "#SBATCH --output=/home/chengar2/geneD/picard_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/picard_%A.err\n",
    "\n",
    "\n",
    "start=`date +%s`\n",
    "echo job submitted on $(date) to $HOSTNAME\n",
    "\n",
    "module load picard/2.13\n",
    "\n",
    "for bam in /scratch/chengar2/geneD/bam/*.bam\n",
    "do\n",
    "    extract=$(echo $bam | awk -F\".\" '{print $1}')\n",
    "    name=$(echo $extract | awk -F\"/\" '{print $NF}')\n",
    "    echo \"running analysis for $name on $(date)\"\n",
    "    java -jar /cm/shared/apps/picard/2.13/picard.jar ValidateSamFile I=$bam MODE=SUMMARY \\\n",
    "    O=/scratch/chengar2/geneD/bam/sorted_$name.txt\n",
    "    echo \"analysis complete for $name on $(date)\"\n",
    "done\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "echo job completed on $(date) taking $runtime seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Alignment metrics\n",
    "\n",
    "`I` path to `bam` files  \n",
    "`O` path to save output `bam` files  \n",
    "`R` path to reference genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=picard-MM\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=6\n",
    "#SBATCH --mem=24gb\n",
    "#SBATCH --output=/home/chengar2/geneD/picard-MM_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/picard-MM_%A.err\n",
    "\n",
    "\n",
    "start=`date +%s`\n",
    "echo job submitted on $(date) to $HOSTNAME\n",
    "\n",
    "module load picard/2.13\n",
    "\n",
    "for bam in /scratch/chengar2/geneD/bam/*.bam\n",
    "do\n",
    "    extract=$(echo $bam | awk -F\".\" '{print $1\".\"$2\".\"$3\".\"$4}')\n",
    "    name=$(echo $extract | awk -F\"/\" '{print $NF}')\n",
    "    echo \"running analysis for $name on $(date)\"\n",
    "    java -jar /cm/shared/apps/picard/2.13/picard.jar CollectMultipleMetrics I=$bam O=$extract.multiple_metrics \\\n",
    "    R=/scratch/chengar2/geneD/dna/Mus_musculus.GRCm38.dna.primary_assembly.fa\n",
    "    echo \"analysis complete for $name on $(date)\"\n",
    "done\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "echo job completed on $(date) taking $runtime seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark/RMDuplicates\n",
    "\n",
    "`I` path to `bam` files  \n",
    "`O` path to save output `bam` files  \n",
    "`M` path to save metrics  \n",
    "`REMOVE_DUPLICATES` if set to `true` will remove reads from `bam` entirely; otherwise reads will be marked (0x400 SAM flag will   be added to reads). This can be left out if downstream application can ignore the marked reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=mark_dup\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=6\n",
    "#SBATCH --mem=40gb\n",
    "#SBATCH --output=/home/chengar2/geneD/dup_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/dup_%A.err\n",
    "\n",
    "\n",
    "start=`date +%s`\n",
    "echo job submitted on $(date) to $HOSTNAME\n",
    "\n",
    "module load picard/2.13\n",
    "\n",
    "for bam in /scratch/chengar2/geneD/bam/*.sorted.bam\n",
    "do\n",
    "\textract=$(echo $bam | awk -F\".\" '{print $1\".\"$2\".\"$3\".\"$4}')\n",
    "\tname=$(echo $extract | awk -F\"/\" '{print $NF}')\n",
    "\techo \"running analysis for $name on $(date)\"\n",
    "\tjava -jar /cm/shared/apps/picard/2.13/picard.jar MarkDuplicates I=$bam \\\n",
    "\tO=/scratch/chengar2/geneD/bam/no-dup_$name.bam M=/scratch/chengar2/geneD/bam/dup-metrics_$name.txt \\\n",
    "\tREMOVE_DUPLICATES=true\n",
    "\techo \"analysis complete for $name on $(date)\"\n",
    "done\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "echo job completed on $(date) taking $runtime seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort by queryname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Quality (MAPQ)\n",
    "\n",
    "I found this ancient blog post about `bowtie2`'s MAPQ: http://biofinysics.blogspot.com/2014/05/how-does-bowtie2-assign-mapq-scores.html\n",
    "\n",
    "The take home is that lower the MAPQ, lower the confidence in the alignment. This could be due to mismatch between the reads and the reference sequence, a gap, N's penalty, multiple alignment etc. At the end of the day the equation: MAPQ=-10log10(probability of misalignment) stands correct.\n",
    "\n",
    "Even though `hisat2` is supposedly bulit on `bowtie2`, the MAPQ scoring behavior seems to differ drastically. According to this thread https://www.biostars.org/p/244106/, and also the results of our own `bam` files generated by `hisat2`, there is only 3 possible value of MAPQ: 0, 1, and 60. The comment made by `prasundutta87` in the thread suggests reads with MAPQ of 60 are unqiue reads and anything lower means they have secondary alignment. However `Fabio Marroni` pointed out he has reads with MAPQ of 60 but have multiple alignments, leading us to this thread https://www.biostars.org/p/295354/. `Macspider`'s comment (somewhat) confirms that MAPQ 60 doesn't neccessarily guarantee the read(s) to be unqiuely mapped. \n",
    "\n",
    "So all in all filtering out reads that has a MAPQ lower than 2 seems to be the most stringent strategy we can have, which rougly translates to discarding 10-15% of the reads...not a small number but maybe it is worth it for the extra accuracy (?). Now I also wonder whether we should filter out non-primary alignments and/or multiple alignments...things are getting more complicated! But for now I will filter out the \"low quality\" alignments and leave it as that.\n",
    "\n",
    "If you need more affirmation to filter reads in `bam` files: https://biostar.usegalaxy.org/p/28856/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code to filter out reads in the `bam` file with MAPQ <2. Depends on the downstream package used, this might be not necessary.  \n",
    "`-@` no. of threads  \n",
    "`-q` is set to 2, the minimum MAPQ we want  \n",
    "`-b` is used to specify inputs are `bam` files  \n",
    "`-h` is set to include `bam` header in output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=filter\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=6\n",
    "#SBATCH --mem=24gb\n",
    "#SBATCH --output=/home/chengar2/geneD/filter_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/filter_%A.err\n",
    "\n",
    "module load samtools/1.9\n",
    "\n",
    "start=`date +%s`\n",
    "echo job submitted on $(date) to $HOSTNAME\n",
    "\n",
    "for bam in /scratch/chengar2/geneD/bam/no-dup*\n",
    "do\n",
    "    extract=$(echo $bam | awk -F\".\" '{print $1}')\n",
    "    name=$(echo $extract | awk -F\"_\" '{print $NF}')\n",
    "    echo \"running analysis for $name on $(date)\"\n",
    "    samtools view -@ 6 -bhq 2 $bam > /scratch/chengar2/geneD/filtered_bam/filtered_$name.bam\n",
    "    echo \"analysis complete for $name on $(date)\"\n",
    "done\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "echo job completed on $(date) taking $runtime seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index bam\n",
    "\n",
    "This step is required if you wish to visualize the alignment result in IGV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=index_bam\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=6\n",
    "#SBATCH --mem=24gb\n",
    "#SBATCH --output=/home/chengar2/geneD/index-bam_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/index-bam_%A.err\n",
    "\n",
    "start=`date +%s`\n",
    "echo job submitted on $(date) to $HOSTNAME\n",
    "\n",
    "module load samtools/1.9\n",
    "\n",
    "for bam in /scratch/chengar2/geneD/filtered_bam/*.bam\n",
    "    samtools index $bam\n",
    "done\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "echo job completed on $(date) taking $runtime seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Some program such as `picard`'s `MarkDuplicates` required the `bam` files to be sorted by coordinate. However `featureCounts` required the files to be sorted by queryname (otherwise some files might be mistaken as single-end sequencing). Use `-n` flag if you need to sort by queryname."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used `summarizeOverlaps` from `GenomicAlignments` to do read-counting before, however the package is not very friendly if we wish to do strand-specific counting, dropping low quality reads, and ignoring duplicated reads all at once. `featureCounts` from `subread` seems to be easier to implement without too much trouble especially it is already installed in our cluster so we can utilize the powerful computer for counting. The authors also released an R version of the program called `Rsubread`. You can run it on R if you want.\n",
    "\n",
    "Note that read counting is rather convoluted if one wish to only count the exons that code for protein (i.e. ignore reads that aligned to lnc RNA, pseudogenes, retained intron etc.) and would not be reliable without advance modeling in isoform expression. To my understanding, this is because an exon that is transcribed and translated in a protein could also be expressed in a non-protein coding transcript, making the reads that aligned to it rather difficult to categorize without information on individual transcript abundance. This might be worth exploring in the future; for now I would let the program count all read alignments and summarize by \"gene_id\".\n",
    "\n",
    "\n",
    "Dr. Friederike Dundar wrote a very detail manual on RNA-seq and **Chapter 4** has extensive details on gene-based read counting vs Isoform counting. Make sure you have a read https://github.com/friedue/course_RNA-seq2017/blob/master/Intro2RNAseq.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below is for read-counting with the package `subread`. \n",
    "\n",
    "`-T` no. of threads to use  \n",
    "`-p` is used to specify all files contain pair-end reads  \n",
    "`-a` the path to the annotation file used (from ensembl; see the `wget` section)  \n",
    "`-t` count reads aligned to exon...  \n",
    "`-g` summarized by the meta-feature \"gene_id\"  \n",
    "`-Q` is set to the minimum MAPQ score required  \n",
    "`-s` is set to 2, i.e. library strand = first strand. Program will conduct strand-specific counting and ignore unpaired reads because their strandness cannot be determined  \n",
    "`--ignoreDup` is used  \n",
    "`-o` specify output file name or path\n",
    "\n",
    "Note there is a lot of different approach we can take here. Change the code accordingly to explore different options.\n",
    "1. To drop duplicate reads or not (~10-15% of alignments)\n",
    "2. To conduct strand-specific counting or not (some libraries see increased % alignment assignment when strandness is considered due to lower `Unassigned_Ambiguity`)\n",
    "3. To drop low quality reads or not (~10%-15% of alignments)\n",
    "\n",
    "There is also options to allow multi-mapping reads to be counted or allow reads to overlap multiple genes in one alignment, you can try them out if you are interested (I don't think they are useful in your case). \n",
    "\n",
    "I have also tried changing the `-g` flag to \"transcript_id\" and \"exon\", hoping that will allow us to filter out non-protein coding transcripts/exons down the line. Make sure you also use the `-O` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=picard_fm\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem=40gb\n",
    "#SBATCH --output=/home/chengar2/geneD/picard_fm_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/picard_fm_%A.err\n",
    "\n",
    "start=`date +%s`\n",
    "echo job submitted on $(date) to $HOSTNAME\n",
    "\n",
    "module load subread/1.6.4\n",
    "\n",
    "bam=/scratch/chengar2/geneD/bam/md_fm*.qsort.bam\n",
    "featureCounts -T 10 -p -a /scratch/chengar2/geneD/gtf/Mus_musculus.GRCm38.98.gtf.gz -t exon -g gene_id \\\n",
    "-Q 2 -s 2 --ignoreDup \\\n",
    "-o counts.txt $bam\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "echo job completed on $(date) taking $runtime seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work with the data in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the `txt` file from `featureCounts`, we will have to switch over to `R` to continue the analysis.  \n",
    "\n",
    "This is a very useful link with step-by-step instructions on using `DESeq2`: http://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html\n",
    "\n",
    "Here's another demo for `DESeq2`: https://www.bioconductor.org/packages/devel/workflows/vignettes/rnaseqGene/inst/doc/rnaseqGene.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(DESeq2)\n",
    "library(dplyr)\n",
    "library(tidyr)\n",
    "setwd(\"Z:/Arthur/rna_seq_script\") \n",
    "#or press `ctrl`+`shift`+`H` to change the working directory to where the `txt` count file is located"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the comment regarding pre-analysis filtering I left for myself when I was doing the SOX2 revision.\n",
    "\n",
    "> ### To Filter or Not to Filter  \n",
    ">A note on filtering raw counts before normalization with DESeq2 or edgeR  \n",
    ">- The strength of the filter **does** affect the downstream DE genes identification even though DESeq2 and edgeR both have independent filtering to exclude genes with low count from analysis  \n",
    ">- I think filtering with count-per-million (CPM) is statistically more robust than filtering on the counts directly, as the latter does not account for differences in library sizes between samples.  \n",
    ">- The simplest form of filter is to sum up the counts (or CPM) for a gene across all samples(libraries) and exclude those that are below a random threshold, e.g. 1, 5, 10  \n",
    ">- Another way to filter the data is to exlude genes with low expression (again a random threshold) in the majority of libraries (say only 4 out of 5 libraries)  \n",
    "\n",
    "For the SOX2 revision I took the last approach to filter out genes with low expression in EXCEL. You can open up the `txt` file in EXCEL (because it is tab delimited). First calculate CPM for individual genes (gene_count/total_count_in_library) and then pick a random threshold you like and decide how many libraries is considered \"the majority\". Once you have done that, exclude genes that fail to meet the threshold, and save the file (as csv, tsv, or txt).\n",
    " \n",
    "Now load it into `R`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts <- read.csv(\"nd-ss-q2-gene_id.txt\",sep=\"\\t\", row.names = \"Geneid\")\n",
    "head(cts)\n",
    "colnames(cts)\n",
    "\n",
    "#the column names are crazy long; simplify them!\n",
    "colnames(cts)<-sub(\"X.scratch.chengar2.geneD.bam.md_fm_\", \"\", colnames(cts))\n",
    "colnames(cts)\n",
    "colnames(cts)<-sub(\".pri.hisat2.qsort.bam\", \"\", colnames(cts))\n",
    "colnames(cts)\n",
    "\n",
    "#you don't need the chr, start, end, strand, and length columns. take them out if you haven't done so\n",
    "#this only contains 16 samples, modify the code after you have the full set of 20\n",
    "cts<-cts[6:21]\n",
    "cts\n",
    "\n",
    "#now make another matrix/dataframe that contains the experimental factors\n",
    "colnames(cts)\n",
    "sample<-colnames(cts)\n",
    "sample\n",
    "\n",
    "genotype<-c(rep(\"KO\",10), rep(\"WT\", 10))\n",
    "genotype\n",
    "\n",
    "trt<-c(rep(c(\"DD\",\"LP\"),10))\n",
    "\n",
    "#a is KO-DD\n",
    "#b is KO-LP\n",
    "#c is WT-DD\n",
    "#d is WT-LP\n",
    "group<-c(rep(c(\"a\",\"b\"),5), rep(c(\"c\",\"d\"),5)\n",
    "\n",
    "#make the data frame\n",
    "coldata<-data.frame(sample,genotype,trt,group)\n",
    "coldata\n",
    "rownames(coldata)<-coldata[,1]\n",
    "coldata[,1]<-NULL\n",
    "coldata\n",
    "\n",
    "#make sure all info are correct in coldata\n",
    "#make sure all info are correct in coldata\n",
    "#make sure all info are correct in coldata\n",
    "\n",
    "#it is also important that all info in coldata is matching the order of the libraries in cts\n",
    "all(row.names(coldata) %in% colnames(cts))\n",
    "all(row.names(coldata) == colnames(cts))\n",
    "\n",
    "#method 1a: the \"normal\"/\"simplest\" way\n",
    "dds <-DESeqDataSetFromMatrix(countData = cts, colData = coldata, design = ~group)\n",
    "dds\n",
    "dds <- DESeq(dds)\n",
    "deg_dd <- results(dds, contrast=c(\"group\",\"a\",\"c\"))\n",
    "deg_lp <- results(dds, contrast=c(\"group\",\"b\",\"d\"))\n",
    "ko_induct <- results(dds, contrast=c(\"group\",\"b\",\"a\")) #not a 100% sure if this is right\n",
    "wt_induct <- results(dds, contrast=c(\"group\",\"d\",\"c\")) #not a 100% sure if this is right\n",
    "write.csv(deg_dd, \"./res/deg_dd.csv\") #make sure a folder called \"res\" exsists in your working dir before you run\n",
    "write.csv(deg_lp, \"./res/deg_lp.csv\")\n",
    "write.csv(wt_induct, \"./res/wt_induct.csv\")\n",
    "write.csv(ko_induct, \"./res/ko_induct.csv\")\n",
    "\n",
    "#method 1b: stop DESeq2 from changing the padj to NA when read count is low\n",
    "dds <-DESeqDataSetFromMatrix(countData = cts, colData = coldata, design = ~group)\n",
    "dds\n",
    "dds <- DESeq(dds)\n",
    "deg_dd <- results(dds, contrast=c(\"group\",\"a\",\"c\"), independentFiltering = FALSE)\n",
    "deg_lp <- results(dds, contrast=c(\"group\",\"b\",\"d\"), independentFiltering = FALSE)\n",
    "ko_induct <- results(dds, contrast=c(\"group\",\"b\",\"a\"), independentFiltering = FALSE) #not a 100% sure if this is right\n",
    "wt_induct <- results(dds, contrast=c(\"group\",\"d\",\"c\"), independentFiltering = FALSE) #not a 100% sure if this is right\n",
    "write.csv(deg_dd, \"./nofil/nf_deg_dd.csv\") #make sure a folder called \"res\" exsists in your working dir before you run\n",
    "write.csv(deg_lp, \"./nofil/nf_deg_lp.csv\")\n",
    "write.csv(wt_induct, \"./nofil/nf_wt_induct.csv\")\n",
    "write.csv(ko_induct, \"./nofil/nf_ko_induct.csv\")\n",
    "\n",
    "#method2: extract the condition/interaction effect\n",
    "dds <-DESeqDataSetFromMatrix(countData = cts, colData = coldata, design = ~ genotype + trt + genotype:trt)\n",
    "dds\n",
    "dds$genotype <- factor(dds$genotype, level=c(\"WT\",\"KO\"))\n",
    "levels(dds$genotype)\n",
    "dds <- DESeq(dds)\n",
    "resultsNames(dds)\n",
    "res_nofil<-results(dds, name=\"genotypeKO.trtLP\", independentFiltering = FALSE) #toggle \"independentFiltering\" when necessary\n",
    "write.csv(res_nofil, file=\"./res1/nofil.csv\")\n",
    "\n",
    "#method3: LRT test\n",
    "dds <- DESeqDataSetFromMatrix(countData = cts, colData = coldata, design = ~ genotype + trt + genotype:trt)\n",
    "dds\n",
    "dds$genotype <- factor(dds$genotype, level=c(\"WT\",\"KO\"))\n",
    "levels(dds$genotype)\n",
    "dds <- DESeq(dds, test=\"LRT\", reduced = ~ genotype + trt)\n",
    "resultsNames(dds)\n",
    "lrt<-results(dds, independentFiltering = FALSE)\n",
    "write.csv(lrt, file=\"./res1/lrt.csv\")    \n",
    "         \n",
    "\n",
    "#get the normalized count; this would be useful for plotting graphs\n",
    "norm_count<-(counts(dds, normalized=TRUE))\n",
    "write.csv(norm_count, \"./res/norm_count.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of DEGs expression\n",
    "\n",
    "Don't bother with this before the full set of data is acquired; we need to identify the DEGs before we plot the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsd<-vst(dds,blind=FALSE) #transform the dds using VST\n",
    "\n",
    "#filter out the nonDEGs\n",
    "DEG<-read.csv(\"deseq2_237degs_fdr.05.csv\", header=TRUE) #list of ensemblID for the 237 DEGs\n",
    "filter<-rownames(vsd)%in%DEG$ensemblID\n",
    "degonly<-vsd[filter,]\n",
    "\n",
    "#make a matrix of expression minus mean expression\n",
    "mat<-assay(degonly)-rowMeans(assay(degonly))\n",
    "anno <- as.data.frame(colData(vsd)[, c(\"genotype\",\"time_h\")])\n",
    "pheatmap(mat, annotation_col = anno, cluster_cols = FALSE)\n",
    "\n",
    "#this is borrowed from https://slowkow.com/notes/heatmap-tutorial/ to make each color represent the same number of blocks\n",
    "quantile_breaks <- function(xs, n = 10) {\n",
    "breaks <- quantile(xs, probs = seq(0, 1, length.out = n))\n",
    "breaks[!duplicated(breaks)]\n",
    "}\n",
    "mat_breaks <- quantile_breaks(mat, n = 11)\n",
    "res<-pheatmap(mat, annotation_col = anno, cluster_cols = FALSE, color= viridis(length(mat_breaks) - 1),\n",
    "breaks= mat_breaks, show_colnames = F, show_rownames = F)\n",
    "\n",
    "#sorting the dendrogram\n",
    "library(dendsort)\n",
    "library(dendextend)\n",
    "sort_hclust <- function(...) as.hclust(dendsort(as.dendrogram(...)))\n",
    "mat_cluster_cols <- sort_hclust(res$tree_row)\n",
    "res<-pheatmap(mat, annotation_col = anno, cluster_cols = FALSE, cluster_rows = rev(mat_cluster_cols), \n",
    "              color= viridis(length(mat_breaks)-1), breaks= mat_breaks, show_colnames = F, show_rownames = F, cutree_rows = 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (NOT done yet) Adapter trim only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract element(s) from string\n",
    "ls *txt |awk -F\".\" '{print $2}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interactive section with cluster\n",
    "srun --pty -p generalq -t 0-12:00 -c 4 --mem 8G /bin/bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract MAPQ from sam/bam and export to file\n",
    "samtools view no-dup_fixed_mate_KO1-DD1.pri.hisat2.sorted.bam | awk -F \"\\t\" '{print $5}' > mapq.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate average MAPQ score\n",
    "more mapq.txt | awk '{total += $1; count ++ } END {print total/count}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code is for fixing `HEADER_RECORD_MISSING_REQUIRED_TAG` and `MISSING_PLATFORM_VALUE` with Picard `AddOrReplaceReadGroups` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=generalq\n",
    "#SBATCH --job-name=picard_rg\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=6\n",
    "#SBATCH --mem=24gb\n",
    "#SBATCH --output=/home/chengar2/geneD/picard_rg_%A.out\n",
    "#SBATCH --error=/home/chengar2/geneD/picard_rg_%A.err\n",
    "\n",
    "\n",
    "start=`date +%s`\n",
    "echo job submitted on $(date) to $HOSTNAME\n",
    "\n",
    "module load picard/2.13\n",
    "\n",
    "for sam in /scratch/chengar2/geneD/qual_trim/*.sam\n",
    "do\n",
    "    extract=$(echo $sam | awk -F\".\" '{print $1}')\n",
    "    name=$(echo $extract | awk -F\"/\" '{print $NF}')\n",
    "    echo \"running analysis for $name on $(date)\"\n",
    "    java -jar /cm/shared/apps/picard/2.13/picard.jar AddOrReplaceReadGroups I=$sam \\\n",
    "    O=/scratch/chengar2/geneD/qual_trim/rg_$name.sam \\\n",
    "    RGID=geneD_$name \\\n",
    "    RGLB=lib1 \\\n",
    "    RGPL=illumina \\\n",
    "    RGPU=unit1 \\\n",
    "    RGSM=$name \\\n",
    "    VALIDATION_STRINGENCY=SILENT\n",
    "    echo \"analysis complete for $name on $(date)\"\n",
    "done\n",
    "\n",
    "end=`date +%s`\n",
    "runtime=$((end-start))\n",
    "echo job completed on $(date) taking $runtime seconds"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
